import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import argparse
import time
import warnings
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor
import psutil
import os
import sys
from functools import partial

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
try:
    from sklearn.metrics import silhouette_score
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  scikit-learn –Ω–µ –Ω–∞–π–¥–µ–Ω - –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    SKLEARN_AVAILABLE = False

try:
    from numba import jit, prange
    NUMBA_AVAILABLE = True
    print("‚úÖ Numba –¥–æ—Å—Ç—É–ø–Ω–∞ - —É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ")
except ImportError:
    print("‚ö†Ô∏è  Numba –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ - —Ä–∞–±–æ—Ç–∞ –±–µ–∑ JIT")
    NUMBA_AVAILABLE = False
    def jit(*args, **kwargs):
        def decorator(func): return func
        return decorator
    def prange(*args, **kwargs):
        return range(*args, **kwargs)

warnings.filterwarnings('ignore')

# –ë—ã—Å—Ç—Ä—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
class ProgressBar:
    """–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä"""
    def __init__(self, total, description="–ü—Ä–æ–≥—Ä–µ—Å—Å"):
        self.total = total
        self.current = 0
        self.description = description
        self.start_time = time.time()

    def update(self, step=1):
        self.current += step
        if self.current % max(1, self.total // 20) == 0 or self.current == self.total:
            progress = self.current / self.total
            elapsed = time.time() - self.start_time
            eta = elapsed / progress - elapsed if progress > 0 else 0

            bar_length = 30
            filled = int(bar_length * progress)
            bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)

            print(f"\r{self.description}: [{bar}] {progress*100:.1f}% "
                  f"(ETA: {eta:.1f}s)", end="", flush=True)

            if self.current == self.total:
                print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ –∫–æ–Ω—Ü–µ

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
if NUMBA_AVAILABLE:
    @jit(nopython=True, parallel=True)
    def fast_distances(pixels, centroids):
        n_pixels, n_features = pixels.shape
        n_clusters = centroids.shape[0]
        distances = np.zeros((n_pixels, n_clusters))

        for i in prange(n_pixels):
            for k in range(n_clusters):
                dist = 0.0
                for j in range(n_features):
                    diff = pixels[i, j] - centroids[k, j]
                    dist += diff * diff
                distances[i, k] = dist
        return distances

    @jit(nopython=True, parallel=True)
    def fast_assignments(distances, sigma):
        n_pixels, n_clusters = distances.shape
        assignments = np.zeros((n_pixels, n_clusters))

        for i in prange(n_pixels):
            min_dist = np.min(distances[i])
            exp_sum = 0.0
            exp_values = np.zeros(n_clusters)

            for k in range(n_clusters):
                exp_values[k] = np.exp(-(distances[i, k] - min_dist) / (2 * sigma * sigma))
                exp_sum += exp_values[k]

            for k in range(n_clusters):
                assignments[i, k] = exp_values[k] / exp_sum

        return assignments

    @jit(nopython=True)
    def fast_silhouette_sample(distances_to_centroids, labels, n_clusters):
        """–ë—ã—Å—Ç—Ä–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è silhouette –¥–ª—è –≤—ã–±–æ—Ä–∫–∏"""
        n_samples = len(labels)
        silhouette_values = np.zeros(n_samples)

        for i in range(n_samples):
            # –í–Ω—É—Ç—Ä–∏–∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–¥–æ —Å–≤–æ–µ–≥–æ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞)
            own_cluster = labels[i]
            a_i = distances_to_centroids[i, own_cluster]

            # –ë–ª–∏–∂–∞–π—à–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –¥—Ä—É–≥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
            b_i = np.inf
            for k in range(n_clusters):
                if k != own_cluster:
                    if distances_to_centroids[i, k] < b_i:
                        b_i = distances_to_centroids[i, k]

            # Silhouette –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
            if max(a_i, b_i) > 0:
                silhouette_values[i] = (b_i - a_i) / max(a_i, b_i)
            else:
                silhouette_values[i] = 0.0

        return silhouette_values

else:
    def fast_distances(pixels, centroids):
        return np.sum((pixels[:, np.newaxis] - centroids)**2, axis=2)

    def fast_assignments(distances, sigma):
        exp_values = np.exp(-distances / (2 * sigma**2))
        return exp_values / np.sum(exp_values, axis=1, keepdims=True)

    def fast_silhouette_sample(distances_to_centroids, labels, n_clusters):
        n_samples = len(labels)
        silhouette_values = np.zeros(n_samples)

        for i in range(n_samples):
            own_cluster = labels[i]
            a_i = distances_to_centroids[i, own_cluster]

            other_distances = distances_to_centroids[i, [k for k in range(n_clusters) if k != own_cluster]]
            b_i = np.min(other_distances) if len(other_distances) > 0 else a_i

            if max(a_i, b_i) > 0:
                silhouette_values[i] = (b_i - a_i) / max(a_i, b_i)

        return silhouette_values


class FastMultithreadClustering:
    """–ë—ã—Å—Ç—Ä–∞—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""

    def __init__(self, n_clusters=3, learning_rate=0.01, max_iter=100,
                 tolerance=1e-4, sigma=1.0, n_threads=None, random_state=42):

        self.n_clusters = n_clusters
        self.learning_rate = learning_rate
        self.initial_lr = learning_rate
        self.max_iter = max_iter
        self.tolerance = tolerance
        self.sigma = sigma
        self.random_state = random_state

        if n_threads is None:
            self.n_threads = min(mp.cpu_count(), 6)
        else:
            self.n_threads = min(n_threads, mp.cpu_count())

        self.centroids = None
        self.labels = None
        self.loss_history = []
        self.converged = False
        self.n_iter = 0

        np.random.seed(random_state)
        print(f"üöÄ –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {self.n_threads} –ø–æ—Ç–æ–∫–æ–≤, {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

    def _kmeans_plus_plus_init(self, X):
        """–ë—ã—Å—Ç—Ä–∞—è K-means++ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤...")
        n_samples, n_features = X.shape
        centroids = np.zeros((self.n_clusters, n_features))

        centroids[0] = X[np.random.randint(n_samples)]

        for i in range(1, self.n_clusters):
            distances = np.array([
                min([np.sum((x - c)**2) for c in centroids[:i]])
                for x in X
            ])

            probabilities = distances / distances.sum()
            cumulative_probs = probabilities.cumsum()
            r = np.random.random()

            for j, prob in enumerate(cumulative_probs):
                if r <= prob:
                    centroids[i] = X[j]
                    break

        print("‚úÖ –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return centroids

    def _compute_batch_parallel(self, X_batch):
        """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞"""
        distances = fast_distances(X_batch, self.centroids)
        assignments = fast_assignments(distances, self.sigma)
        loss = np.sum(assignments * distances) / len(X_batch)
        return assignments, loss, distances

    def _compute_assignments_and_loss_fast(self, X):
        """–£–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
        if len(X) < 2000:  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
            return self._compute_batch_parallel(X)

        # –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ - –±–∞—Ç—á–∞–º–∏ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
        batch_size = max(500, len(X) // self.n_threads)
        batches = [X[i:i+batch_size] for i in range(0, len(X), batch_size)]

        progress = ProgressBar(len(batches), "üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–µ–π")

        def process_with_progress(batch_idx_and_data):
            batch_idx, batch_data = batch_idx_and_data
            result = self._compute_batch_parallel(batch_data)
            progress.update()
            return result

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        with ThreadPoolExecutor(max_workers=self.n_threads) as executor:
            batch_data = [(i, batch) for i, batch in enumerate(batches)]
            results = list(executor.map(process_with_progress, batch_data))

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_assignments = np.vstack([r[0] for r in results])
        avg_loss = np.mean([r[1] for r in results])
        all_distances = np.vstack([r[2] for r in results])

        return all_assignments, avg_loss, all_distances

    def fit(self, X):
        """–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ"""
        print(f"\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {len(X)} –ø–∏–∫—Å–µ–ª—è—Ö...")
        start_time = time.time()

        self.centroids = self._kmeans_plus_plus_init(X)
        prev_centroids = self.centroids.copy()
        self.loss_history = []

        for iteration in range(self.max_iter):
            # –ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–π
            assignments, loss, _ = self._compute_assignments_and_loss_fast(X)
            self.loss_history.append(loss)

            # –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã
            gradients = np.zeros_like(self.centroids)
            for k in range(self.n_clusters):
                weights = assignments[:, k:k+1]
                if np.sum(weights) > 1e-8:
                    weighted_diff = weights * (self.centroids[k] - X)
                    gradients[k] = 2 * np.mean(weighted_diff, axis=0)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            self.centroids -= self.learning_rate * gradients
            self.learning_rate = self.initial_lr * np.exp(-0.001 * iteration)

            # –°—Ö–æ–¥–∏–º–æ—Å—Ç—å
            centroid_shift = np.mean(np.sqrt(np.sum((self.centroids - prev_centroids)**2, axis=1)))

            if iteration % 20 == 0:
                print(f"   –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration:3d}: Loss={loss:.6f}, Shift={centroid_shift:.6f}")

            if centroid_shift < self.tolerance:
                print(f"‚úÖ –°—Ö–æ–¥–∏–º–æ—Å—Ç—å –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {iteration}")
                self.converged = True
                break

            prev_centroids = self.centroids.copy()

        self.n_iter = iteration + 1

        # –ë–´–°–¢–†–´–ï —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
        print("üîÑ –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è...")
        final_assignments, _, self.final_distances = self._compute_assignments_and_loss_fast(X)
        self.labels = np.argmax(final_assignments, axis=1)

        total_time = time.time() - start_time
        print(f"üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {total_time:.2f}—Å")
        print(f"   –ò—Ç–µ—Ä–∞—Ü–∏–π: {self.n_iter}")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {len(X) * self.n_iter / total_time:.0f} –ø–∏–∫—Å/—Å–µ–∫")

        return self

    def get_fast_metrics(self, X, sample_size=5000):
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –Ω–∞ –≤—ã–±–æ—Ä–∫–µ"""
        print(f"üìä –ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (–≤—ã–±–æ—Ä–∫–∞: {min(sample_size, len(X))})...")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if len(X) > sample_size:
            indices = np.random.choice(len(X), sample_size, replace=False)
            sample_X = X[indices]
            sample_labels = self.labels[indices]
            sample_distances = self.final_distances[indices]
        else:
            sample_X = X
            sample_labels = self.labels
            sample_distances = self.final_distances

        metrics = {}

        # –ë—ã—Å—Ç—Ä–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è Silhouette Score
        if SKLEARN_AVAILABLE and len(np.unique(sample_labels)) > 1:
            try:
                print("üîÑ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Silhouette Score...")
                if NUMBA_AVAILABLE:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—é
                    silhouette_values = fast_silhouette_sample(
                        sample_distances, sample_labels, self.n_clusters
                    )
                    metrics['silhouette_score'] = np.mean(silhouette_values)
                else:
                    # Fallback –Ω–∞ sklearn —Å –≤—ã–±–æ—Ä–∫–æ–π
                    if len(sample_X) > 1000:  # –ï—â–µ –±–æ–ª—å—à–µ —É–º–µ–Ω—å—à–∞–µ–º –≤—ã–±–æ—Ä–∫—É
                        sub_indices = np.random.choice(len(sample_X), 1000, replace=False)
                        metrics['silhouette_score'] = silhouette_score(
                            sample_X[sub_indices], sample_labels[sub_indices]
                        )
                    else:
                        metrics['silhouette_score'] = silhouette_score(sample_X, sample_labels)
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ Silhouette Score: {e}")
                metrics['silhouette_score'] = 0.0
        else:
            metrics['silhouette_score'] = 0.0

        # –ë—ã—Å—Ç—Ä–∞—è –∫–∞—Ä—Ç–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö)
        print("üîÑ –ö–∞—Ä—Ç–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏...")
        confidence_sample_size = min(1000, len(X))
        if len(X) > confidence_sample_size:
            conf_indices = np.random.choice(len(X), confidence_sample_size, replace=False)
            conf_distances = self.final_distances[conf_indices]
        else:
            conf_distances = self.final_distances

        # –ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        conf_assignments = fast_assignments(conf_distances, self.sigma)
        sorted_probs = np.sort(conf_assignments, axis=1)
        confidence_sample = sorted_probs[:, -1] - sorted_probs[:, -2]
        metrics['avg_confidence'] = np.mean(confidence_sample)

        print("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã—á–∏—Å–ª–µ–Ω—ã –±—ã—Å—Ç—Ä–æ!")
        return metrics

    def create_fast_visualization(self, original_image, pixels, shape, save_only=False):
        """–ë—ã—Å—Ç—Ä–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –∑–∞–≤–∏—Å–∞–Ω–∏–π"""
        print("üìä –ë—ã—Å—Ç—Ä–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è...")

        try:
            # –ë—ã—Å—Ç—Ä–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            clustered_pixels = self.centroids[self.labels]
            clustered_image = (clustered_pixels * 255).astype(np.uint8).reshape(original_image.shape)

            if save_only:
                # –¢–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–µ–∑ –ø–æ–∫–∞–∑–∞
                fig, axes = plt.subplots(1, 2, figsize=(12, 5))
                fig.suptitle('–ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è', fontsize=14)

                axes[0].imshow(original_image)
                axes[0].set_title('–ò—Å—Ö–æ–¥–Ω–æ–µ')
                axes[0].axis('off')

                axes[1].imshow(clustered_image)
                axes[1].set_title('–†–µ–∑—É–ª—å—Ç–∞—Ç')
                axes[1].axis('off')

                plt.tight_layout()
                plt.savefig('clustering_result.png', dpi=150, bbox_inches='tight')
                plt.close()  # –í–∞–∂–Ω–æ –∑–∞–∫—Ä—ã—Ç—å!

                print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ clustering_result.png")
            else:
                # –ü–æ–ª–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                fig, axes = plt.subplots(2, 3, figsize=(15, 10))
                fig.suptitle('üöÄ –ë—ã—Å—Ç—Ä–∞—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è', fontsize=16)

                # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                axes[0, 0].imshow(original_image)
                axes[0, 0].set_title('–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
                axes[0, 0].axis('off')

                # –†–µ–∑—É–ª—å—Ç–∞—Ç
                axes[0, 1].imshow(clustered_image)
                axes[0, 1].set_title('–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏')
                axes[0, 1].axis('off')

                # –ü–∞–ª–∏—Ç—Ä–∞
                palette = np.ones((50, self.n_clusters * 50, 3))
                for i, color in enumerate(self.centroids):
                    palette[:, i*50:(i+1)*50] = color

                axes[0, 2].imshow(palette)
                axes[0, 2].set_title('–ü–∞–ª–∏—Ç—Ä–∞')
                axes[0, 2].axis('off')

                # –ö–∞—Ä—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—É–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
                cluster_map = self.labels.reshape(shape)
                if max(shape) > 500:  # –£–º–µ–Ω—å—à–∞–µ–º –±–æ–ª—å—à–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    from PIL import Image as PILImage
                    cluster_img = PILImage.fromarray((cluster_map * 25).astype(np.uint8))
                    cluster_img = cluster_img.resize((min(500, shape[1]), min(500, shape[0])))
                    cluster_map = np.array(cluster_img)

                im1 = axes[1, 0].imshow(cluster_map, cmap='tab10')
                axes[1, 0].set_title('–ö–∞—Ä—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
                axes[1, 0].axis('off')

                # –ì—Ä–∞—Ñ–∏–∫ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                axes[1, 1].plot(self.loss_history, 'b-', linewidth=2)
                axes[1, 1].set_title('–°—Ö–æ–¥–∏–º–æ—Å—Ç—å')
                axes[1, 1].set_xlabel('–ò—Ç–µ—Ä–∞—Ü–∏—è')
                axes[1, 1].set_ylabel('–ü–æ—Ç–µ—Ä–∏')
                axes[1, 1].grid(True)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                axes[1, 2].text(0.1, 0.8, f'–ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {self.n_clusters}', transform=axes[1, 2].transAxes, fontsize=12)
                axes[1, 2].text(0.1, 0.7, f'–ò—Ç–µ—Ä–∞—Ü–∏–π: {self.n_iter}', transform=axes[1, 2].transAxes, fontsize=12)
                axes[1, 2].text(0.1, 0.6, f'–ü–∏–∫—Å–µ–ª–µ–π: {len(pixels)}', transform=axes[1, 2].transAxes, fontsize=12)
                axes[1, 2].text(0.1, 0.5, f'–ü–æ—Ç–æ–∫–æ–≤: {self.n_threads}', transform=axes[1, 2].transAxes, fontsize=12)
                axes[1, 2].text(0.1, 0.4, f'–°—Ö–æ–¥–∏–º–æ—Å—Ç—å: {"–î–∞" if self.converged else "–ù–µ—Ç"}', transform=axes[1, 2].transAxes, fontsize=12)
                axes[1, 2].set_title('–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞')
                axes[1, 2].axis('off')

                plt.tight_layout()

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å —Ç–∞–π–º-–∞—É—Ç–æ–º
                try:
                    plt.show(block=False)
                    plt.pause(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
                    print("‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞")

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–ø–∏—é
                    plt.savefig('clustering_result.png', dpi=150, bbox_inches='tight')
                    print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ clustering_result.png")

                except Exception as e:
                    print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –ø–æ–∫–∞–∑–µ: {e}")
                    plt.savefig('clustering_result.png', dpi=150, bbox_inches='tight')
                    print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ clustering_result.png")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            print("üíæ –ü–æ–ø—ã—Ç–∫–∞ –±–∞–∑–æ–≤–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è...")

            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            clustered_pixels = self.centroids[self.labels]
            clustered_image = (clustered_pixels * 255).astype(np.uint8).reshape(original_image.shape)
            Image.fromarray(clustered_image).save('clustering_result_basic.png')
            print("‚úÖ –ë–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω")


def create_test_image(filename="test_fast.png"):
    """–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    print(f"üé® –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {filename}")

    img = Image.new('RGB', (300, 300), color='white')
    from PIL import ImageDraw
    draw = ImageDraw.Draw(img)

    # –ü—Ä–æ—Å—Ç—ã–µ —Ñ–∏–≥—É—Ä—ã
    draw.ellipse([50, 50, 150, 150], fill=(255, 0, 0))
    draw.ellipse([150, 150, 250, 250], fill=(0, 255, 0))
    draw.rectangle([20, 200, 80, 280], fill=(0, 0, 255))
    draw.rectangle([220, 20, 280, 80], fill=(255, 255, 0))

    img.save(filename)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ: {filename}")
    return filename


def main():
    """–ë—ã—Å—Ç—Ä–∞—è –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ë–´–°–¢–†–ê–Ø –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è')
    parser.add_argument('image_path', nargs='?', help='–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é')
    parser.add_argument('--clusters', '-k', type=int, default=3, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
    parser.add_argument('--learning_rate', '-lr', type=float, default=0.01, help='–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--max_iter', '-i', type=int, default=100, help='–ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π')
    parser.add_argument('--threads', '-t', type=int, default=11, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤')
    parser.add_argument('--fast_mode', action='store_true', help='–¢–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏')
    parser.add_argument('--save_only', action='store_true', help='–¢–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å, –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å')
    parser.add_argument('--create_test', action='store_true', help='–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')

    args = parser.parse_args()

    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if args.create_test:
            test_file = create_test_image()
            if not args.image_path:
                args.image_path = test_file

        if not args.image_path:
            args.image_path = create_test_image()

        if not os.path.exists(args.image_path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.image_path}")
            return 1

        # –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
        print(f"üì∑ –ó–∞–≥—Ä—É–∑–∫–∞: {args.image_path}")
        start_load = time.time()

        with Image.open(args.image_path) as img:
            if img.mode != 'RGB':
                img = img.convert('RGB')
            original_image = np.array(img)

        h, w, c = original_image.shape
        pixels = original_image.reshape(-1, c).astype(np.float32) / 255.0

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞ {time.time() - start_load:.2f}—Å: {len(pixels)} –ø–∏–∫—Å–µ–ª–µ–π")

        # –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        model = FastMultithreadClustering(
            n_clusters=args.clusters,
            learning_rate=args.learning_rate,
            max_iter=args.max_iter,
            n_threads=args.threads
        )

        # –û–±—É—á–µ–Ω–∏–µ
        model.fit(pixels)

        # –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if not args.fast_mode:
            metrics = model.get_fast_metrics(pixels)
            print(f"üìà Silhouette Score: {metrics['silhouette_score']:.4f}")
            print(f"üìà –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {metrics['avg_confidence']:.4f}")

        # –ë—ã—Å—Ç—Ä–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        model.create_fast_visualization(
            original_image, pixels, (h, w),
            save_only=args.save_only
        )

        print("\nüéâ –ë–´–°–¢–†–ê–Ø –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --fast_mode –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏")
        print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --save_only —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–∫–∞–∑–∞ –æ–∫–æ–Ω")

        return 0

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    print("üñ•Ô∏è  –ë–´–°–¢–†–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø:")
    print(f"   CPU —è–¥–µ—Ä: {mp.cpu_count()}")
    print(f"   RAM: {psutil.virtual_memory().total / 1024**3:.1f} –ì–ë")
    print(f"   Numba: {'–î–∞' if NUMBA_AVAILABLE else '–ù–µ—Ç'}")
    print(f"   Sklearn: {'–î–∞' if SKLEARN_AVAILABLE else '–ù–µ—Ç'}")
    print("-" * 50)

    exit(main())
